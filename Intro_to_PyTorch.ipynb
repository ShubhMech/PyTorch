{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "identical-statement",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-blame",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-snowboard",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasicNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__() \n",
    "\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
    "        \n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
    "\n",
    "        self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        top_relu_output = F.relu(input_to_top_relu)\n",
    "        scaled_top_relu_output = top_relu_output * self.w01\n",
    "        \n",
    "        \n",
    "        input_to_bottom_relu = input * self.w10 + self.b10\n",
    "        bottom_relu_output = F.relu(input_to_bottom_relu)\n",
    "        scaled_bottom_relu_output = bottom_relu_output * self.w11\n",
    "        \n",
    "        \n",
    "        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n",
    "        \n",
    "        output = F.relu(input_to_final_relu)\n",
    "    \n",
    "        return output \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BasicNN()\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-outreach",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_doses = torch.linspace(start=0, end=1, steps=11)\n",
    "\n",
    "\n",
    "input_doses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-writing",
   "metadata": {},
   "source": [
    "Now that we have `input_doses`, let's run them through the neural network and graph the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BasicNN() \n",
    "\n",
    "\n",
    "output_values = model(input_doses)\n",
    "\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "sns.lineplot(x=input_doses, \n",
    "             y=output_values, \n",
    "             color='green', \n",
    "             linewidth=2.5)\n",
    "\n",
    "## now label the y- and x-axes.\n",
    "plt.ylabel('Effectiveness')\n",
    "plt.xlabel('Dose')\n",
    "\n",
    "## optionally, save the graph as a PDF.\n",
    "# plt.savefig('BasicNN.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-arthur",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-rocket",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-tension",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasicNN_train(nn.Module):\n",
    "\n",
    "    def __init__(self): \n",
    "        \n",
    "        super().__init__() # initialize an instance of the parent class, nn.Module.\n",
    "        \n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
    "        \n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
    "\n",
    "\n",
    "        self.final_bias = nn.Parameter(torch.tensor(0.), requires_grad=True) \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        top_relu_output = F.relu(input_to_top_relu)\n",
    "        scaled_top_relu_output = top_relu_output * self.w01\n",
    "        \n",
    "        input_to_bottom_relu = input * self.w10 + self.b10\n",
    "        bottom_relu_output = F.relu(input_to_bottom_relu)\n",
    "        scaled_bottom_relu_output = bottom_relu_output * self.w11\n",
    "    \n",
    "        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n",
    "        \n",
    "        output = F.relu(input_to_final_relu)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the neural network. \n",
    "model = BasicNN_train() \n",
    "\n",
    "## now run the different doses through the neural network.\n",
    "output_values = model(input_doses)\n",
    "\n",
    "## Now draw a graph that shows the effectiveness for each dose.\n",
    "##\n",
    "## set the style for seaborn so that the graph looks cool.\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "## create the graph (you might not see it at this point, but you will after we save it as a PDF).\n",
    "sns.lineplot(x=input_doses, \n",
    "             y=output_values.detach(), ## NOTE: because final_bias has a gradident, we call detach() \n",
    "                                       ## to return a new tensor that only has the value and not the gradient.\n",
    "             color='green', \n",
    "             linewidth=2.5)\n",
    "\n",
    "## now label the y- and x-axes.\n",
    "plt.ylabel('Effectiveness')\n",
    "plt.xlabel('Dose')\n",
    "\n",
    "## lastly, save the graph as a PDF.\n",
    "# plt.savefig('BasicNN_train.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training data for the neural network.\n",
    "inputs = torch.tensor([0., 0.5, 1.])\n",
    "labels = torch.tensor([0., 1., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BasicNN_train()\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.1) \n",
    "\n",
    "print(\"Final bias, before optimization: \" + str(model.final_bias.data) + \"\\n\")\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "        \n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "\n",
    "    for iteration in range(len(inputs)):\n",
    "        \n",
    "        input_i = inputs[iteration] \n",
    "        label_i = labels[iteration] \n",
    "        \n",
    "        output_i = model(input_i) .\n",
    "        \n",
    "        loss = (output_i - label_i)**2 \n",
    "        loss.backward() \n",
    "        \n",
    "        total_loss += float(loss) \n",
    "        \n",
    "        \n",
    "    if (total_loss < 0.0001):\n",
    "        print(\"Num steps: \" + str(epoch))\n",
    "        break\n",
    "      \n",
    "    optimizer.step() \n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    print(\"Step: \" + str(epoch) + \" Final Bias: \" + str(model.final_bias.data) + \"\\n\")\n",
    "    \n",
    "\n",
    "print(\"Total loss: \" + str(total_loss))\n",
    "print(\"Final bias, after optimization: \" + str(model.final_bias.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_values = model(input_doses)\n",
    "\n",
    ".\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "sns.lineplot(x=input_doses, \n",
    "             y=output_values.detach()\n",
    "             color='green', \n",
    "             linewidth=2.5)\n",
    "\n",
    "\n",
    "plt.ylabel('Effectiveness')\n",
    "plt.xlabel('Dose')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
